# 1 网络分层结构

|OSI	|TCP/IP|	数据包	|功能|
|-|-|-|-|
|⑦应用层	|④应用层	|报文|	解决通过应用进程之间的交互来实现特定网络应用的问题|
|⑥表示层|||			解决通信双方交换信息的表示问题|
|⑤会话层	|||		解决进程之间进行会话问题|
|④运输层|	③运输层|	TCP报文段	|解决进程之间基于网络的通信问题|
|③网络层|	②网际层	|IP数据报|	解决分组在多个网络之间传输（路由）的问题|
|②数据链路层|	①网络接口层|	帧	|解决分组在一个网络（或一段链路）上传输的问题|
|①物理层|	|	比特流	|解决使用何种信号来传输比特0和1的问题|


- 五层模型：应用层、传输层、网络层、数据链路层、物理层。

> 应用层：为应用程序提供交互服务。在互联网中的应用层协议很多，如域名系统DNS、HTTP协议、SMTP协议等。
> 
> 传输层：负责向两台主机进程之间的通信提供数据传输服务。传输层的协议主要有传输控制协议TCP和用户数据协议UDP。
> 
> 网络层：选择合适的路由和交换结点，确保数据及时传送。主要包括IP协议。
> 
> 数据链路层：在两个相邻节点之间传送数据时，数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧。
> 
> 物理层：实现相邻节点间比特流的透明传输，尽可能屏蔽传输介质和物理设备的差异。

# 2 三次握手

![image](https://user-images.githubusercontent.com/72682213/189035299-66f5e0d5-e1b6-4732-8b90-5736a3923a36.png)

最初两端的TCP进程都处于CLOSED关闭状态，A主动打开连接，而B被动打开连接。（A、B关闭状态CLOSED——B收听状态LISTEN——A同步已发送状态SYN-SENT——B同步收到状态SYN-RCVD——A、B连接已建立状态ESTABLISHED）

- 三次握手过程

第一次握手：起初两端都处于CLOSED关闭状态，Client将标志位SYN置为1（请求建立连接），随机产生一个值seq=x，将该数据包发送给Server，Client进入SYN-SENT状态，等待Server确认；

第二次握手：Server收到数据包后由标志位SYN=1得知Client请求建立连接，Server将标志位SYN（同步标志位）和ACK（确认标志位）都置为1，ack=x+1，随机产生一个起始序列号seq=y，将该数据包发送给Client以确认连接请求。握手前是Listen状态，握手后进入SYN-RCVD状态，此时操作系统为该TCP连接分配TCP缓存和变量；

第三次握手：Client收到确认后，检查ack是否为x+1，ACK是否为1，如果正确则将标志位ACK置为1，ack=y+1，并且此时操作系统为该TCP连接分配TCP缓存和变量，并将该数据包发送给Server，进入ESTABLISHED状态。Server检查ack是否为y+1，ACK是否为1，如果正确则连接建立成功，Server进入ESTABLISHED状态，完成三次握手。

随后Client和Server就可以开始传输数据。


- 可以二次握手吗？

1、因为信道不可靠，而TCP想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而UDP则不需建立可靠传输，因此UDP不需要三次握手。）

2、双方都需要确认对方收到了自己发送的初始化序列号，确认过程最少要进行三次通信。

3、为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。

> 比如客户端A发出连接请求，可能因为网络阻塞原因，A没有收到确认报文，于是A再重传一次连接请求。
>
> 连接成功，等待数据传输完毕后，就释放了连接。
>
> 然后A发出的第一个连接请求等到连接释放以后的某个时间才到达服务端B，此时B误认为A又发出一次新的连接请求，于是就向A发出确认报文段。
>
> 如果不采用三次握手，B发出确认，就建立新的连接了，此时A不会响应B的确认且不发送数据，则B一直等待A发送数据，浪费资源。

- ISN

三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。

如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。

- 半连接队列、全连接

服务器第一次收到客户端的SYN之后，就会处于SYN_RCVD状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。

全连接队列：已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。

- 三次握手携带数据

第三次握手可以携带数据。客户端已经处于 established 状态，并且也已经知道服务器的接收、发送能力是正常的了。

- Server端易受到SYN攻击？

服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到SYN洪泛攻击。

> SYN攻击就是Client在短时间内伪造大量不存在的IP地址，并向Server不断地发送SYN包
> 
> Server回复确认包，并等待Client确认，
>
> 由于源地址不存在，因此Server需要不断重发直至超时
> 
> 这些伪造的SYN包将长时间占用未连接队列，导致正常的SYN请求因为队列满而被丢弃，从而引起网络拥塞甚至系统瘫痪。

防范SYN攻击措施：降低主机的等待时间使主机尽快的释放半连接的占用，短时间受到某IP的重复SYN则丢弃后续请求。

# 4. 四次挥手

![image](https://user-images.githubusercontent.com/72682213/189035597-5876ac39-0afd-4185-b9c9-cb7bbd508aa8.png)

AB处于ESTABLISHED状态——A发出释放报文段处于FIN-WAIT-1状态——B发出确认报文段进入CLOSE-WAIT状态——A收到确认进入FIN-WAIT-2状态，等待B的连接释放报文段 —— B发出连接释放报文段且进入LAST-ACK状态 —— A发出确认报文段且进入TIME-WAIT状态 —— B收到确认报文段后进入CLOSED状态 —— A经过等待计时器时间2MSL后，进入CLOSED状态。

## 4.1四次挥手过程

- A的应用进程先向其TCP发出连接释放报文段（FIN=1，seq=u），并停止再发送数据，主动关闭TCP连接，进入FIN-WAIT-1（终止等待1）状态，等待B的确认。

- B收到连接释放报文段后即发出确认报文段（ACK=1，ack=u+1，seq=v），B进入CLOSE-WAIT（关闭等待）状态，此时的TCP处于半关闭状态，A到B的连接释放。A收到B的确认后，进入FIN-WAIT-2（终止等待2）状态，等待B发出的连接释放报文段。

- B发送完数据，就会发出连接释放报文段（FIN=1，ACK=0，seq=w，ack=u+1），B进入LAST-ACK（最后确认）状态，等待A的确认。

- A收到B的连接释放报文段后，对此发出确认报文段（ACK=1，seq=u+1，ack=w+1），A进入TIME-WAIT（时间等待）状态。此时TCP未释放掉，需要经过时间等待计时器设置的时间2MSL（最大报文段生存时间）后，A才进入CLOSED状态。B收到A发出的确认报文段后关闭连接，若没收到A发出的确认报文段，B就会重传连接释放报文段。


## 4.2第四次挥手为什么要等待2MSL

MSL最长报文段寿命Maximum Segment Lifetime，MSL=2

1）保证A发送的最后一个ACK报文段能够到达B。

这个ACK报文段有可能丢失，使得处于LAST-ACK状态的B收不到对已发送的FIN+ACK报文段的确认，B超时重传FIN+ACK报文段，而A能在2MSL时间内收到这个重传的FIN+ACK报文段，接着A重传一次确认，重新启动2MSL计时器，最后A和B都进入到CLOSED状态，若A在TIME-WAIT状态不等待一段时间，而是发送完ACK报文段后立即释放连接，则无法收到B重传的FIN+ACK报文段，所以不会再发送一次确认报文段，则B无法正常进入到CLOSED状态。

2）防止“已失效的连接请求报文段”出现在本连接中。

A在发送完最后一个ACK报文段后，再经过2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失，使下一个新的连接中不会出现这种旧的连接请求报文段。

## 4.3为什么连接的时候是三次握手，关闭的时候却是四次握手？

当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。

但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。

只有等到Server端所有的报文都发送完了，才能发送FIN报文，因此不能一起发送。

## 4.4状态

LISTEN – 侦听来自远方TCP端口的连接请求；

SYN-SENT -在发送连接请求后等待匹配的连接请求；

SYN-RECEIVED – 在收到和发送一个连接请求后等待对连接请求的确认；

ESTABLISHED- 代表一个打开的连接，数据可以传送给用户；

FIN-WAIT-1 – 等待远程TCP的连接中断请求，或先前的连接中断请求的确认；

FIN-WAIT-2 – 从远程TCP等待连接中断请求；

CLOSE-WAIT – 等待从本地用户发来的连接中断请求；

CLOSING -等待远程TCP对连接中断的确认；

LAST-ACK – 等待原来发向远程TCP的连接中断请求的确认；

TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认；

CLOSED – 没有任何连接状态；

# 6. TCP和UDP特点、应用层协议、应用场景

- 特点

| TCP | UDP |
|-|-|
|面向连接的运输层协议                       | 无连接的，即发送数据之前不需要建立连接|
|可靠交付的服务                                |不保证可靠交付|
|面向字节流,把数据看成一连串无结构的字节流   |面向报文|
|每一条TCP连接只能是点到点的                |支持一对一、一对多、多对一和多对多的通信方式|
|有拥塞控制|  没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如实时视频会议等）    |
|首部20个字节|首部8个字节|
|全双工通信|          |

 - 基于TCP的应用层协议有：HTTP、FTP、SMTP、TELNET、SSH

效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有UDP高。举几个例子：文件传输（准确高要求高、但是速度可以相对慢）、接受邮件、远程登录。

> HTTP：HyperText Transfer Protocol（超文本传输协议），默认端口80
> 
> FTP: File Transfer Protocol (文件传输协议), 默认端口(20用于传输数据，21用于传输控制信息)
> 
> SMTP: Simple Mail Transfer Protocol (简单邮件传输协议) ,默认端口25
> 
> TELNET: Teletype over the Network (网络电传), 默认端口23
>  
> SSH：Secure Shell（安全外壳协议），默认端口 22

- 基于UDP的应用层协议：DNS、TFTP、SNMP

效率要求相对高，对准确性要求相对低的场景。举几个例子：QQ聊天、在线视频、网络语音电话（即时通讯，速度要求高，但是出现偶尔断续不是太大问题，并且此处完全不可以使用重发机制）、广播通信（广播、多播）

> DNS : Domain Name Service (域名服务),默认端口 53
>
> TFTP: Trivial File Transfer Protocol (简单文件传输协议)，默认端口69
>
> SNMP：Simple Network Management Protocol（简单网络管理协议），通过UDP端口161接收，只有Trap信息采用UDP端口162。

# 5. TCP报文首部

![image](https://user-images.githubusercontent.com/72682213/189035937-0ea0caac-bc00-4915-8c0d-85b2542b17f5.png)

- 16位端口号：源端口号，主机该报文段是来自哪里；目标端口号，要传给哪个上层协议或应用程序

- 32位序号：一次TCP通信（从TCP连接建立到断开）过程中某一个传输方向上的字节流的每个字节的编号。

- 32位确认号：用作对另一方发送的tcp报文段的响应。其值是收到的TCP报文段的序号值加1。

- 4位头部长度：表示tcp头部有多少个32bit字（4字节）。因为4位最大能标识15，所以TCP头部最长是60字节。

- 6位标志位：URG(紧急指针是否有效)，ACk（表示确认号是否有效），PSH（缓冲区尚未填满），RST（表示要求对方重新建立连接），SYN（建立连接消息标志接），FIN（表示告知对方本端要关闭连接了）

- 16位窗口大小：是TCP流量控制的一个手段。这里说的窗口，指的是接收通告窗口。它告诉对方本端的TCP接收缓冲区还能容纳多少字节的数据，这样对方就可以控制发送数据的速度。

- 16位校验和：由发送端填充，接收端对TCP报文段执行CRC算法以检验TCP报文段在传输过程中是否损坏。注意，这个校验不仅包括TCP头部，也包括数据部分。这也是TCP可靠传输的一个重要保障。

- 16位紧急指针：一个正的偏移量。它和序号字段的值相加表示最后一个紧急数据的下一字节的序号。因此，确切地说，这个字段是紧急指针相对当前序号的偏移，不妨称之为紧急偏移。TCP的紧急指针是发送端向接收端发送紧急数据的方法。

# 7. TCP沾包/拆包

- 问题
TCP是面向字节流的（UDP基于报文），“流” 意味着TCP所传输的数据是没有边界的。TCP底层并不了解上层业务数据的具体含义，它会根据TCP缓冲区的实际情况进行包的划分，所以在业务上认为，一个完整的包可能会被TCP拆分成多个包进行发送，也有可能把多个小的包封装成一个大的数据包发送，这就是所谓的TCP粘包和拆包问题。

- 原因

> 要发送的数据小于TCP发送缓冲区的大小，TCP将多次写入缓冲区的数据一次发送出去，将会发生粘包；
>
> 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包；
> 
> 要发送的数据大于TCP发送缓冲区剩余空间大小，将会发生拆包；（放数据的速度 > 应用层拿数据速度）
>
> 待发送数据大于MSS（最大报文长度），TCP在传输前将进行拆包。即TCP报文长度-TCP头部长度>MSS。

- 解决：
> 1. 发送端将每个数据包封装为固定长度。
> 
> 2. 包头加上包体长度。包头是定长的4个字节，说明了包体的长度。接收方先接收包头长度，依据包头长度来接收包体。
> 
> 3. 在数据包之间设置边界，如添加特殊符号\r\n标记。FTP协议正是这么做的。但问题在于如果数据正文中也含有\r\n，则会误判为消息的边界。
> 
> 4. 使用更加复杂的应用层协议。

- 为什么等缓冲区满了才发送?

缓冲区的优势以文件流的写入为例，如果我们不使用缓冲区，每次写操作CPU都会和低速存储设备也就是磁盘进行交互，那么整个写入文件的速度就会受制于低速的存储设备（磁盘）。但如果使用缓冲区的话，每次写操作会先将数据保存在高速缓冲区内存上，当缓冲区的数据到达某个阈值之后，再将文件一次性写入到磁盘上。因为内存的写入速度远远大于磁盘的写入速度，所以当有了缓冲区之后，文件的写入速度就被大大提升了。

# 8. TCP是如何确保可靠性

可靠传输有如下两个特点：

> a.传输信道无差错,保证传输数据正确；
> 
> b.不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据（流量控制）。

- （1）采用三次握手来建立TCP连接，四次挥手来释放TCP连接，从而保证建立的传输信道是可靠的。
- 
- （2）TCP采用了连续ARQ协议（回退N，Go-back-N；超时自动重传）来保证数据传输的正确性，使用滑动窗口协议保证接收方能够及时处理所接收到的数据，进行流量控制。

- TCP的可靠性，还体现在有状态;TCP会记录哪些数据发送了，哪些数据被接收了，哪些没有被接受，并且保证数据包按序到达，保证数据传输不出差错。
- TCP的可靠性，还体现在可控制。它有数据包校验、ACK应答、超时重传(发送方)、失序数据重传（接收方）、丢弃重复数据、流量控制（滑动窗口）和拥塞控制等机制。


数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据。

对失序数据包重排序：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。TCP 将对失序数据进行重新排序，然后才交给应用层；
丢弃重复数据：对于重复数据，能够丢弃重复数据。

应答机制：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒。

超时重发：当TCP发出一个段后，启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。

流量控制：TCP连接的每一方都有固定大小的缓冲空间。TCP的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP使用的流量控制协议是可变大小的滑动窗口协议。

- （3）最后，TCP使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制，避免网络拥塞。


TCP是面向连接的、可靠的、传输层通信协议。可靠体现在：
有状态：TCP会确认发送了哪些报文，接收方受到了哪些报文，哪些没有收到，保证数据包按序到达，不允许有差错。
可控制：如果出现丢包或者网络状况不佳，则会跳转自己的行为，减少发送的速度或者重发，所以上面能保证数据包的有效传输。

# 9. TCP流量控制、滑动窗口

TCP利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。接收方发送的确认报文中的window字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。

TCP会话的双方都各自维护一个发送窗口和一个接收窗口。接收窗口大小取决于应用、系统、硬件的限制。发送窗口则取决于对端通告的接收窗口。

TCP利用滑动窗口实现流量控制的机制。早期的网络通信中，通信双方不会考虑网络的拥挤情况直接发送数据。由于大家不知道网络拥塞状况，同时发送数据，导致中间节点阻塞掉包，谁也发不了数据，所以就有了滑动窗口机制来解决此问题。

TCP中采用滑动窗口来进行传输控制，滑动窗口的大小意味着接收方还有多大的缓冲区可以用于接收数据。发送方可以通过滑动窗口的大小来确定应该发送多少字节的数据。当滑动窗口为0时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个1字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。

![image](https://user-images.githubusercontent.com/72682213/189038407-1ec95555-2d01-40ee-b14e-c52ca02876c0.png)

TCP头包含window字段，16bit位，它代表的是窗口的字节容量，最大为65535。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。接收窗口的大小是约等于发送窗口的大小。

# 10. 拥塞控制

在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变差，这种情况就叫**拥塞**。

**拥塞控制**就是为了防止过多的数据注入到网络中，这样就可以使网络中的路由器或链路不至于过载。

为了进行拥塞控制，TCP发送方要维持一个**拥塞窗口**（cwdn）的状态变量。拥塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。

TCP的**拥塞控制方法**：：慢开始( slow-start )、拥塞避免( congestion avoidance )、快重传( fast retransmit )和快恢复( fast recovery )。

![image](https://user-images.githubusercontent.com/72682213/189038437-af863964-c723-4013-92dc-7a82dc669735.png)

- 慢开始

> 把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。每经过一个传输轮次，拥塞窗口 cwnd 就加倍。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。
>
> 当 cwnd < ssthresh 时，使用慢开始算法。
>
> 当 cwnd > ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。
>
> 当 cwnd = ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。

- 拥塞避免

> 让拥塞窗口cwnd缓慢地增大，每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长。
>
> 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。
> 
> 然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。

- 快重传

有时个别报文段会在网络中丢失，但实际上网络并未发生拥塞。如果发送方迟迟收不到确认，就会产生超时，就会误认为网络发生了拥塞。这就导致发送方错误地启动慢开始，把拥塞窗口cwnd又设置为1，因而降低了传输效率。

快重传算法可以避免这个问题。快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认，使发送方及早知道有报文段没有到达对方。

发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段，而不必继续等待重传计时器到期。由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。

- 快恢复

///如果发送端收到3个重复确认，发现丢包，就将拥塞阈值降低为拥塞窗口的一半，拥塞窗口大小为拥塞阈值，然后拥塞窗口进行线性增加。

当发送方连续收到三个重复确认，就会把慢开始门限ssthresh减半，接着把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法，使拥塞窗口缓慢地线性增大。

在采用快恢复算法时，慢开始算法只是在TCP连接建立时和网络出现超时时才使用。 采用这样的拥塞控制方法使得TCP的性能有明显的改进。

# 11. HTTP协议
## 11.1 请求响应步骤

HTTP协议采用了请求/响应模型。

> 客户端向服务器发送一个请求报文，请求报文包含：请求的方法、URL、协议版本、请求头部和请求数据。
> 
> 服务器以一个状态行作为响应，响应的内容包括：协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。

- 1. 客户端连接到Web服务器

一个HTTP客户端，通常是浏览器，与Web服务器的HTTP端口（默认为80）建立一个TCP套接字连接。例如，http://www.baidu.com。

- 2. 发送HTTP请求

通过TCP套接字，客户端向Web服务器发送一个文本的请求报文，一个请求报文由请求行、请求头部、空行和请求数据4部分组成。

- 3. 服务器接受请求并返回HTTP响应

Web服务器解析请求，定位请求资源。服务器将资源复本写到TCP套接字，由客户端读取。一个响应由状态行、响应头部、空行和响应数据4部分组成。

- 4. 释放连接TCP连接

若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;

- 5. 客户端浏览器解析HTML内容

客户端浏览器首先解析状态行，查看表明请求是否成功的状态代码。然后解析每一个响应头，响应头告知以下为若干字节的HTML文档和文档的字符集。客户端浏览器读取响应数据HTML，根据HTML的语法对其进行格式化，并在浏览器窗口中显示。

> 浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;
> 解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;
> 浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;
> 服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;
> 释放 TCP连接;
> 浏览器将该 html 文本格式化并显示内容; 　

## HTTP1.0，1.1，2.0 的版本区别

## HTTP 哪些常用的状态码及使用场景？

## HTTP状态码301和302的区别，都有哪些用途？

## HTTP 如何实现长连接？在什么时候会超时？

## GET请求中URL编码的意义

## 简单说下 HTTPS 和 HTTP 的区别

## 对称加密与非对称加密的区别

## 谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？

## HTTPS 的工作过程？

## HTTP 方法有哪些？

## 在浏览器中输入 URL 地址到显示主页的过程？

## DNS 的解析过程？

## 谈谈你对域名缓存的了解？

## 谈下你对 HTTP 长连接和短连接的理解？分别应用于哪些场景？

## HTTPS 的优缺点？

## URI和 URL之间的区别


## 简单说下怎么实现 DNS 劫持

## DNS 为什么用 UDP





算机网络：HTTP，HTTP请求报文格式、GET和POST、TCP和UDP

1、TCP、UDP可以绑定相同的端口吗？多个TCP进程可以绑定同一个端口吗？
2、什么情况下，可以重新利用这个端口？
3、介绍一下time_wait是一个什么状态，为什么需要这个状态，有什么作用？
4、time_wait状态会带来什么副作用吗？
5、同步IO和异步IO介绍一下？
